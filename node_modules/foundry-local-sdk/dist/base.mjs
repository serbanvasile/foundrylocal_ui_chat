const version = "0.5.0";

async function fetchWithErrorHandling(fetch, url, options) {
  try {
    const response = await fetch(url, options);
    if (!response.ok) {
      let responseContent = "";
      try {
        responseContent = await response.text();
      } catch (error) {
        responseContent = "Unable to read response content";
      }
      return Promise.reject(new Error(`HTTP error! status: ${response.status}, response: ${responseContent}`));
    }
    return response;
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : "Unknown error occurred";
    throw new Error(
      `Network error! Please check if the foundry service is running and the host URL is correct. Error: ${errorMessage}`
    );
  }
}
const get = async (fetch, host, queryParams) => {
  const endpoint = host + (queryParams ? "?" + new URLSearchParams(queryParams).toString() : "");
  return await fetchWithErrorHandling(fetch, endpoint);
};
function parsePercentage(line) {
  const match = line.match(/(\d+(?:\.\d+)?)%/);
  return match ? Math.min(parseInt(match[1]), 100) : null;
}
const postWithProgress = async (fetch, host, body, onProgress) => {
  const response = await fetchWithErrorHandling(fetch, host, {
    method: "POST",
    headers: { "Content-Type": "application/json", "User-Agent": `foundry-local-js-sdk/${version}` },
    body: body ? JSON.stringify(body) : void 0
  });
  const reader = response.body?.getReader();
  let finalJson = "";
  let prevPercent = 0;
  while (true) {
    const { done, value } = await reader?.read() ?? {
      done: true,
      value: new Uint8Array()
    };
    if (done) {
      break;
    }
    const line = new TextDecoder("utf-8").decode(value);
    if (finalJson || line.startsWith("{")) {
      finalJson += line;
      continue;
    }
    if (!onProgress) {
      continue;
    }
    const percent = parsePercentage(line);
    if (percent !== null && percent > prevPercent) {
      prevPercent = percent;
      onProgress(percent);
    }
  }
  if (finalJson) {
    try {
      return JSON.parse(finalJson);
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : "Unknown error occurred";
      throw new Error(`Error parsing JSON response: ${errorMessage}`);
    }
  } else {
    throw new Error("No JSON data received!");
  }
};

var DeviceType = /* @__PURE__ */ ((DeviceType2) => {
  DeviceType2["CPU"] = "CPU";
  DeviceType2["GPU"] = "GPU";
  DeviceType2["NPU"] = "NPU";
  return DeviceType2;
})(DeviceType || {});
var ExecutionProvider = /* @__PURE__ */ ((ExecutionProvider2) => {
  ExecutionProvider2["CPU"] = "CPUExecutionProvider";
  ExecutionProvider2["WEBGPU"] = "WebGpuExecutionProvider";
  ExecutionProvider2["CUDA"] = "CUDAExecutionProvider";
  return ExecutionProvider2;
})(ExecutionProvider || {});

function isWindowsPlatform() {
  if (typeof process !== "undefined" && process.platform) {
    return process.platform === "win32";
  }
  if (typeof navigator !== "undefined" && navigator.platform) {
    return navigator.platform.startsWith("Win");
  }
  return false;
}
let FoundryLocalManager$1 = class FoundryLocalManager {
  /**
   * The service URL for the Foundry service.
   */
  _serviceUrl;
  /**
   * The fetch function to use for HTTP requests.
   */
  fetch;
  /**
   * Cached list of catalog models.
   */
  catalogList = null;
  /**
   * Constructs a new FoundryLocalManager instance.
   * @param {Object} options - Configuration options for the FoundryLocalManager.
   * @param {string} options.serviceUrl - The base URL of the Foundry service.
   * @param {Fetch} [options.fetch] - Optional custom fetch implementation to use for HTTP requests.
   * If not provided, the global fetch will be used.
   */
  constructor({ serviceUrl, fetch: overriddenFetch = fetch }) {
    this._serviceUrl = serviceUrl;
    this.fetch = overriddenFetch;
  }
  /**
   * Gets the service URL.
   * @throws {Error} If the service URL is invalid.
   * @returns {string} The service URL.
   */
  get serviceUrl() {
    if (this._serviceUrl) {
      return this._serviceUrl;
    }
    throw new Error("Service URL is invalid!");
  }
  /**
   * Gets the API endpoint URL.
   * @returns {string} The API endpoint URL.
   */
  get endpoint() {
    return `${this.serviceUrl}/v1`;
  }
  /**
   * Gets the API key.
   * @returns {string} The API key.
   */
  get apiKey() {
    return "OPENAI_API_KEY";
  }
  /**
   * Lists the catalog models.
   * @returns {Promise<FoundryModelInfo[]>} The list of catalog models.
   */
  async listCatalogModels() {
    if (this.catalogList) {
      return this.catalogList;
    }
    const response = await get(this.fetch, `${this.serviceUrl}/foundry/list`);
    const data = await response.json();
    const list = data.map((model) => ({
      alias: model.alias,
      id: model.name,
      version: model.version,
      executionProvider: model.runtime.executionProvider,
      deviceType: model.runtime.deviceType,
      uri: model.uri,
      modelSize: model.fileSizeMb,
      promptTemplate: model.promptTemplate,
      provider: model.providerType,
      publisher: model.publisher,
      license: model.license,
      task: model.task,
      epOverride: null
    }));
    const hasCudaSupport = list.some((mi) => mi.executionProvider === ExecutionProvider.CUDA);
    if (hasCudaSupport) {
      for (const m of list) {
        if (m.id.includes("generic-gpu")) {
          m.epOverride = ExecutionProvider.CUDA.replace("ExecutionProvider", "").toLowerCase();
        }
      }
    }
    this.catalogList = list;
    return this.catalogList;
  }
  /**
   * Extracts numeric version from ID (e.g. model-x:3 â†’ 3)
   * @returns {number} Numeric version extracted from the model ID, or -1 if not found.
   */
  getVersion(modelId) {
    try {
      const versionStr = modelId.split(":")[1];
      const version = parseInt(versionStr, 10);
      return isNaN(version) ? -1 : version;
    } catch {
      return -1;
    }
  }
  /**
   * Refreshes the catalog by clearing cached data.
   * @returns {Promise<void>} Resolves when the catalog is refreshed.
   */
  async refreshCatalog() {
    this.catalogList = null;
  }
  /**
   * Gets the model information of the latest model that matches the given alias or ID.
   * @param {string} aliasOrModelId - The alias or model ID.
   * @param {DeviceType} [device] - Optional device type to filter models.
   * @param {boolean} throwOnNotFound - Whether to throw an error if the model is not found.
   * @returns {Promise<FoundryModelInfo | null>} The model information or null if not found.
   */
  async getModelInfo(aliasOrModelId, device, throwOnNotFound = false) {
    const catalog = await this.listCatalogModels();
    const key = aliasOrModelId.toLowerCase();
    const exact = catalog.find((m) => m.id.toLowerCase() === key);
    if (exact) {
      return exact;
    }
    const prefix = `${key}:`;
    let bestModel = null;
    let bestVersion = -1;
    for (const m of catalog) {
      const idLower = m.id.toLowerCase();
      if (idLower.startsWith(prefix)) {
        const v = this.getVersion(m.id);
        if (v > bestVersion) {
          bestVersion = v;
          bestModel = m;
        }
      }
    }
    if (bestModel) {
      return bestModel;
    }
    let aliasMatches = catalog.filter((m) => m.alias.toLowerCase() === key);
    if (device) {
      aliasMatches = aliasMatches.filter((m) => m.deviceType === device);
    }
    let candidate = aliasMatches[0] ?? null;
    if (candidate && !device && isWindowsPlatform() && candidate.id.includes("-generic-gpu:") && candidate.epOverride == null) {
      const cpuAlt = aliasMatches.find((m) => m.deviceType === DeviceType.CPU);
      if (cpuAlt) {
        candidate = cpuAlt;
      }
    }
    if (!candidate && throwOnNotFound) {
      throw new Error(`Model ${aliasOrModelId} not found in the catalog.`);
    }
    return candidate;
  }
  /**
   * Gets the latest model information by alias or model ID.
   * The difference from getModelInfo is that this method will return the latest version of the model
   * even when you pass it a model id that contains a version suffix.
   * @param {string} aliasOrModelId - The alias or model ID.
   * @param {DeviceType} [device] - Optional device type to filter models.
   * @param {boolean} throwOnNotFound - Whether to throw an error if the model is not found.
   * @returns {Promise<FoundryModelInfo | null>} The model information or null if not found.
   */
  async getLatestModelInfo(aliasOrModelId, device, throwOnNotFound = false) {
    if (!aliasOrModelId) {
      if (throwOnNotFound) {
        throw new Error("The provided model alias or ID was empty.");
      }
      return null;
    }
    const base = aliasOrModelId.split(":")[0];
    return this.getModelInfo(base, device, throwOnNotFound);
  }
  /**
   * Fetches models based on a provided endpoint.
   * @param {string} path - The endpoint path.
   * @returns {Promise<FoundryModelInfo[]>} The list of models.
   */
  async fetchModels(path) {
    const response = await get(this.fetch, `${this.serviceUrl}${path}`);
    const modelNames = await response.json();
    const models = await Promise.all(modelNames.map(async (name) => this.getModelInfo(name)));
    return models.filter((model) => model !== null);
  }
  /**
   * Gets the cache location.
   * @returns {Promise<string>} The cache location.
   */
  async getCacheLocation() {
    const response = await get(this.fetch, `${this.serviceUrl}/openai/status`);
    const data = await response.json();
    return data.modelDirPath;
  }
  /**
   * Lists cached models.
   * @returns {Promise<FoundryModelInfo[]>} The list of models downloaded to the cache.
   */
  async listCachedModels() {
    return await this.fetchModels("/openai/models");
  }
  /**
   * Downloads a model.
   * @param {string} aliasOrModelId - The alias or model ID.
   * @param {DeviceType} [device] - Optional device type to filter models.
   * @param {string} [token] - Optional token for authentication.
   * @param {boolean} force - Whether to force download an already downloaded model.
   * @param {(progress: number) => void} [onProgress] - Callback for download progress percentage.
   * If model is already downloaded and force is false, it will be called once with 100.
   * @returns {Promise<FoundryModelInfo>} The downloaded model information.
   */
  async downloadModel(aliasOrModelId, device, token, force = false, onProgress) {
    const modelInfo = await this.getModelInfo(aliasOrModelId, device, true);
    const cachedModels = await this.listCachedModels();
    if (cachedModels.some((model) => model.id === modelInfo.id)) {
      if (!force) {
        if (onProgress) {
          onProgress(100);
        }
        return modelInfo;
      }
    }
    const downloadBody = {
      Name: modelInfo.id,
      Uri: modelInfo.uri,
      Publisher: modelInfo.publisher,
      ProviderType: modelInfo.provider === "AzureFoundry" ? `${modelInfo.provider}Local` : modelInfo.provider,
      PromptTemplate: modelInfo.promptTemplate
    };
    const body = {
      model: downloadBody,
      ...token && { token },
      IgnorePipeReport: true
    };
    const data = await postWithProgress(this.fetch, `${this.serviceUrl}/openai/download`, body, onProgress);
    if (!data.success) {
      throw new Error(
        `Failed to download model with alias '${modelInfo.alias}' and ID '${modelInfo.id}': ${data.error}`
      );
    }
    return modelInfo;
  }
  /**
   * Checks if a newer version of a model is available.
   * @param {string} aliasOrModelId - The alias or model ID.
   * @param {DeviceType} [device] - Optional device type to filter models.
   * @returns {Promise<boolean>} True if a newer version is available, otherwise false.
   */
  async isModelUpgradeable(aliasOrModelId, device) {
    const modelInfo = await this.getLatestModelInfo(aliasOrModelId, device, true);
    if (!modelInfo) {
      return false;
    }
    const latestVersion = this.getVersion(modelInfo.id);
    if (latestVersion === -1) {
      return false;
    }
    const cachedModels = await this.listCachedModels();
    return !cachedModels.some((m) => m.id == modelInfo.id && this.getVersion(m.id) === latestVersion);
  }
  /**
   * Downloads the latest version of a model to the local cache.
   * @param {string} aliasOrModelId - The alias or model ID.
   * @param {DeviceType} [device] - Optional device type to filter models.
   * @param {string} [token] - Optional token for authentication.
   * @param {(progress: number) => void} [onProgress] - Callback for download progress percentage.
   * @returns {Promise<FoundryModelInfo>} The upgraded model information.
   */
  async upgradeModel(aliasOrModelId, device, token, onProgress) {
    const modelInfo = await this.getLatestModelInfo(aliasOrModelId, device, true);
    return this.downloadModel(modelInfo.id, device, token, false, onProgress);
  }
  /**
   * Loads a model.
   * @param {string} aliasOrModelId - The alias or model ID.
   * @param {DeviceType} [device] - Optional device type to filter models.
   * @param {number} ttl - Time-to-live for the model in seconds. Default is 600 seconds (10 minutes).
   * @returns {Promise<FoundryModelInfo>} The loaded model information.
   * @throws {Error} If the model is not in the catalog or has not been downloaded yet.
   */
  async loadModel(aliasOrModelId, device, ttl = 600) {
    const modelInfo = await this.getModelInfo(aliasOrModelId, device, true);
    const queryParams = { ttl: ttl.toString() };
    if (modelInfo.epOverride) {
      queryParams["ep"] = modelInfo.epOverride;
    }
    try {
      await get(this.fetch, `${this.serviceUrl}/openai/load/${modelInfo.id}`, queryParams);
    } catch (error) {
      if (error instanceof Error && error.message.includes("No OpenAIService provider found for modelName")) {
        throw new Error(`Model ${aliasOrModelId} has not been downloaded yet. Please download it first.`);
      }
      throw error;
    }
    return modelInfo;
  }
  /**
   * Unloads a model.
   * @param {string} aliasOrModelId - The alias or model ID.
   * @param {DeviceType} [device] - Optional device type to filter models.
   * @param {boolean} force - Whether to force unload model with TTL.
   * @returns {Promise<void>} Resolves when the model is unloaded.
   */
  async unloadModel(aliasOrModelId, device, force = false) {
    const modelInfo = await this.getModelInfo(aliasOrModelId, device, true);
    const loadedModels = await this.listLoadedModels();
    if (!loadedModels.some((model) => model.id === modelInfo.id)) {
      return;
    }
    await get(this.fetch, `${this.serviceUrl}/openai/unload/${modelInfo.id}`, {
      force: force.toString()
    });
  }
  /**
   * Lists loaded models.
   * @returns {Promise<FoundryModelInfo[]>} The list of loaded models.
   */
  async listLoadedModels() {
    return await this.fetchModels("/openai/loadedmodels");
  }
};

export { DeviceType, ExecutionProvider, FoundryLocalManager$1 as FoundryLocalManager };
